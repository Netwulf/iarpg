# Story 6.1: AI DM Assistant (Claude Integration)

## Status
Draft

## Story
**As a** DM,
**I want** AI-powered suggestions for story progression, NPC actions, and encounter design,
**so that** I can run engaging sessions with creative assistance.

## Acceptance Criteria
1. DM has access to "AI Assistant" panel in table page (DM only)
2. AI assistant accepts prompts: "Suggest next plot twist", "Create an encounter"
3. Assistant uses Claude API (Anthropic) with game context (table, characters, history)
4. Responses stream in real-time with typing animation
5. DM can copy AI suggestions to chat or save as notes
6. AI context includes: table description, character sheets, recent messages (last 20)
7. Rate limiting: 10 requests per hour for free tier, unlimited for premium
8. AI usage tracked in database (prompt, response, tokens, cost)

## Tasks / Subtasks

- [ ] Create AI Assistant UI panel (AC: 1)
  - [ ] Collapsible panel on right side (below table info)
  - [ ] Only visible to DM
  - [ ] Title: "AI DM Assistant ğŸ¤–"
  - [ ] Input textarea for prompts
  - [ ] "Ask AI" submit button
  - [ ] Response display area with markdown formatting

- [ ] Integrate Claude API (AC: 2, 3)
  - [ ] Install @anthropic-ai/sdk package
  - [ ] Create Claude client with API key from env
  - [ ] Use `claude-3-5-sonnet-20241022` model
  - [ ] Configure max_tokens: 1024
  - [ ] Temperature: 0.7 (creative but coherent)

- [ ] Build game context for AI (AC: 6)
  - [ ] Fetch table details (name, description, tags)
  - [ ] Fetch all character sheets (race, class, level, stats)
  - [ ] Fetch recent messages (last 20)
  - [ ] Fetch active combat state (if any)
  - [ ] Format as structured prompt

- [ ] Create AI assistant API endpoint (AC: 2, 3)
  - [ ] POST `/api/tables/{tableId}/ai/assist`
  - [ ] Validate user is DM
  - [ ] Build context from table data
  - [ ] Call Claude API with streaming
  - [ ] Stream response back to client
  - [ ] Track usage in database

- [ ] Implement streaming responses (AC: 4)
  - [ ] Use Server-Sent Events (SSE) for streaming
  - [ ] Client displays response word-by-word
  - [ ] Show typing animation while streaming
  - [ ] Handle errors gracefully

- [ ] Add quick prompt buttons (AC: 2)
  - [ ] Button: "Suggest Plot Twist"
  - [ ] Button: "Create Encounter"
  - [ ] Button: "Generate NPC"
  - [ ] Button: "Describe Location"
  - [ ] Each pre-fills prompt with template

- [ ] Implement copy/save actions (AC: 5)
  - [ ] "Copy to Clipboard" button
  - [ ] "Send to Chat" button (posts as DM message)
  - [ ] "Save as Note" button (future: table notes feature)

- [ ] Add rate limiting (AC: 7)
  - [ ] Track requests per user per hour
  - [ ] Free tier: 10 requests/hour
  - [ ] Premium tier: unlimited
  - [ ] Show remaining requests in UI
  - [ ] Return 429 error when limit exceeded

- [ ] Track AI usage (AC: 8)
  - [ ] Create AIUsage model in Prisma
  - [ ] Fields: id, userId, tableId, prompt, response, tokensUsed, cost, createdAt
  - [ ] Calculate cost based on Claude pricing
  - [ ] Save after each request

- [ ] Create system prompt template (AC: 3)
  - [ ] Role: "Expert D&D 5e Dungeon Master assistant"
  - [ ] Include game context in prompt
  - [ ] Instructions: helpful, creative, rules-accurate
  - [ ] Tone: enthusiastic but concise

## Dev Notes

### AI Assistant UI Panel
**[Source: PRD Section 3.7.1 - AI Assistant Wireframe]**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI DM ASSISTANT ğŸ¤–              â”‚
â”‚                          [Hide] â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Quick Prompts:                  â”‚
â”‚ [Plot Twist] [Encounter]        â”‚
â”‚ [NPC] [Location]                â”‚
â”‚                                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Your prompt...              â”‚ â”‚
â”‚ â”‚                             â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ [Ask AI] (5/10 requests left)   â”‚
â”‚                                 â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ AI Response:                â”‚ â”‚
â”‚ â”‚                             â”‚ â”‚
â”‚ â”‚ Based on your table's       â”‚ â”‚
â”‚ â”‚ story, here's a twist...    â”‚ â”‚
â”‚ â”‚                             â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ [Copy] [Send to Chat] [Save]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Claude API Integration
**[Source: Anthropic Claude API docs]**

```typescript
// packages/ai/src/claude.ts
import Anthropic from '@anthropic-ai/sdk';

const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

export interface AIAssistRequest {
  prompt: string;
  context: {
    table: {
      name: string;
      description: string;
      tags: string[];
    };
    characters: Array<{
      name: string;
      race: string;
      class: string;
      level: number;
    }>;
    recentMessages: Array<{
      username: string;
      content: string;
    }>;
    combat?: {
      round: number;
      combatants: string[];
    };
  };
}

export async function generateDMAssistance(
  request: AIAssistRequest
): Promise<AsyncIterable<string>> {
  const systemPrompt = buildSystemPrompt(request.context);

  const stream = await anthropic.messages.stream({
    model: 'claude-3-5-sonnet-20241022',
    max_tokens: 1024,
    temperature: 0.7,
    system: systemPrompt,
    messages: [
      {
        role: 'user',
        content: request.prompt,
      },
    ],
  });

  // Return async generator for streaming
  return (async function* () {
    for await (const chunk of stream) {
      if (
        chunk.type === 'content_block_delta' &&
        chunk.delta.type === 'text_delta'
      ) {
        yield chunk.delta.text;
      }
    }
  })();
}

function buildSystemPrompt(context: AIAssistRequest['context']): string {
  return `You are an expert Dungeon Master assistant for D&D 5e. You help DMs run engaging, creative sessions.

**Current Game Context:**

Table: ${context.table.name}
Description: ${context.table.description}
Tags: ${context.table.tags.join(', ')}

**Party:**
${context.characters
  .map(
    (c) => `- ${c.name}: Level ${c.level} ${c.race} ${c.class}`
  )
  .join('\n')}

${
  context.combat
    ? `**Combat Status:**
Round: ${context.combat.round}
Active combatants: ${context.combat.combatants.join(', ')}`
    : ''
}

**Recent Conversation:**
${context.recentMessages
  .map((m) => `${m.username}: ${m.content}`)
  .join('\n')}

**Instructions:**
- Provide helpful, creative suggestions aligned with D&D 5e rules
- Keep responses concise (2-3 paragraphs max)
- Match the tone and setting of the current campaign
- Suggest specific actions, encounters, or story beats
- Be enthusiastic but practical

Respond to the DM's request below:`;
}
```

### API Controller with Streaming
**[Source: Architecture Section 5.1.8 - AI Endpoints]**

```typescript
// apps/api/src/controllers/ai.controller.ts
import { Request, Response, NextFunction } from 'express';
import { prisma } from '@iarpg/db';
import { generateDMAssistance } from '@iarpg/ai';

export const aiController = {
  async assist(req: Request, res: Response, next: NextFunction) {
    try {
      const { tableId } = req.params;
      const userId = req.user!.id;
      const { prompt } = req.body;

      // Verify user is DM
      const table = await prisma.table.findUnique({
        where: { id: tableId },
        include: {
          members: {
            include: {
              character: {
                select: {
                  name: true,
                  race: true,
                  class: true,
                  level: true,
                },
              },
            },
          },
        },
      });

      if (!table || table.ownerId !== userId) {
        return res.status(403).json({ error: 'Only DM can use AI assistant' });
      }

      // Check rate limit
      const user = await prisma.user.findUnique({
        where: { id: userId },
        select: { tier: true },
      });

      if (user?.tier === 'free') {
        const oneHourAgo = new Date(Date.now() - 60 * 60 * 1000);
        const recentUsage = await prisma.aIUsage.count({
          where: {
            userId,
            createdAt: { gte: oneHourAgo },
          },
        });

        if (recentUsage >= 10) {
          return res.status(429).json({
            error: 'Rate limit exceeded. Upgrade to premium for unlimited requests.',
          });
        }
      }

      // Fetch recent messages
      const recentMessages = await prisma.message.findMany({
        where: { tableId },
        include: {
          user: { select: { username: true } },
        },
        orderBy: { createdAt: 'desc' },
        take: 20,
      });

      // Fetch active combat
      const combat = await prisma.combatEncounter.findFirst({
        where: { tableId, state: 'active' },
        include: {
          combatants: {
            select: { name: true },
          },
        },
      });

      // Build context
      const context = {
        table: {
          name: table.name,
          description: table.description,
          tags: table.tags,
        },
        characters: table.members
          .map((m) => m.character)
          .filter(Boolean) as any[],
        recentMessages: recentMessages
          .reverse()
          .map((m) => ({
            username: m.user.username,
            content: m.content,
          })),
        combat: combat
          ? {
              round: combat.round,
              combatants: combat.combatants.map((c) => c.name),
            }
          : undefined,
      };

      // Set up SSE
      res.setHeader('Content-Type', 'text/event-stream');
      res.setHeader('Cache-Control', 'no-cache');
      res.setHeader('Connection', 'keep-alive');

      let fullResponse = '';
      let tokensUsed = 0;

      try {
        const stream = await generateDMAssistance({ prompt, context });

        for await (const chunk of stream) {
          fullResponse += chunk;
          tokensUsed += chunk.split(' ').length; // Rough estimate

          res.write(`data: ${JSON.stringify({ chunk })}\n\n`);
        }

        res.write('data: [DONE]\n\n');
        res.end();

        // Track usage
        const cost = calculateCost(tokensUsed, 'claude-3-5-sonnet-20241022');
        await prisma.aIUsage.create({
          data: {
            userId,
            tableId,
            prompt,
            response: fullResponse,
            tokensUsed,
            cost,
          },
        });
      } catch (error) {
        res.write(`data: ${JSON.stringify({ error: 'AI request failed' })}\n\n`);
        res.end();
      }
    } catch (error) {
      next(error);
    }
  },

  async getRemainingRequests(req: Request, res: Response, next: NextFunction) {
    try {
      const userId = req.user!.id;

      const user = await prisma.user.findUnique({
        where: { id: userId },
        select: { tier: true },
      });

      if (user?.tier === 'premium' || user?.tier === 'master') {
        return res.json({ remaining: 'unlimited' });
      }

      const oneHourAgo = new Date(Date.now() - 60 * 60 * 1000);
      const recentUsage = await prisma.aIUsage.count({
        where: {
          userId,
          createdAt: { gte: oneHourAgo },
        },
      });

      res.json({ remaining: Math.max(0, 10 - recentUsage), limit: 10 });
    } catch (error) {
      next(error);
    }
  },
};

function calculateCost(tokens: number, model: string): number {
  // Claude 3.5 Sonnet pricing (as of 2024)
  const INPUT_COST_PER_1M = 3.0; // $3 per 1M input tokens
  const OUTPUT_COST_PER_1M = 15.0; // $15 per 1M output tokens

  // Estimate: 60% input, 40% output
  const inputTokens = tokens * 0.6;
  const outputTokens = tokens * 0.4;

  const inputCost = (inputTokens / 1_000_000) * INPUT_COST_PER_1M;
  const outputCost = (outputTokens / 1_000_000) * OUTPUT_COST_PER_1M;

  return inputCost + outputCost;
}
```

### AI Assistant Component
```typescript
'use client';

import { useState } from 'react';
import { useSession } from 'next-auth/react';
import ReactMarkdown from 'react-markdown';

interface AIAssistantProps {
  tableId: string;
}

export function AIAssistant({ tableId }: AIAssistantProps) {
  const { data: session } = useSession();
  const [prompt, setPrompt] = useState('');
  const [response, setResponse] = useState('');
  const [loading, setLoading] = useState(false);
  const [remaining, setRemaining] = useState<number | 'unlimited'>(10);

  const quickPrompts = [
    { label: 'Plot Twist', prompt: 'Suggest an exciting plot twist for the current situation' },
    { label: 'Encounter', prompt: 'Create a balanced combat encounter for the party' },
    { label: 'NPC', prompt: 'Generate an interesting NPC with personality and goals' },
    { label: 'Location', prompt: 'Describe a mysterious location the party could explore' },
  ];

  const handleAskAI = async (customPrompt?: string) => {
    const finalPrompt = customPrompt || prompt;
    if (!finalPrompt.trim()) return;

    setLoading(true);
    setResponse('');

    try {
      const response = await fetch(`/api/tables/${tableId}/ai/assist`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ prompt: finalPrompt }),
      });

      if (!response.ok) {
        if (response.status === 429) {
          toast.error('Rate limit exceeded. Upgrade to premium for unlimited requests.');
          return;
        }
        throw new Error('AI request failed');
      }

      const reader = response.body?.getReader();
      const decoder = new TextDecoder();

      if (!reader) throw new Error('No reader available');

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        const chunk = decoder.decode(value);
        const lines = chunk.split('\n\n');

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6);
            if (data === '[DONE]') break;

            try {
              const parsed = JSON.parse(data);
              if (parsed.chunk) {
                setResponse((prev) => prev + parsed.chunk);
              }
            } catch (e) {
              // Skip invalid JSON
            }
          }
        }
      }

      // Update remaining requests
      fetchRemaining();
    } catch (error) {
      toast.error('Failed to get AI response');
    } finally {
      setLoading(false);
    }
  };

  const fetchRemaining = async () => {
    const res = await fetch(`/api/ai/remaining`);
    const data = await res.json();
    setRemaining(data.remaining);
  };

  const handleCopyToClipboard = () => {
    navigator.clipboard.writeText(response);
    toast.success('Copied to clipboard!');
  };

  const handleSendToChat = async () => {
    await fetch(`/api/tables/${tableId}/messages`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ content: response }),
    });
    toast.success('Sent to chat!');
  };

  return (
    <div className="w-96 border-l border-gray-800 p-4 space-y-4">
      <div className="flex items-center justify-between">
        <h2 className="text-h4 font-bold">AI DM Assistant ğŸ¤–</h2>
      </div>

      {/* Quick Prompts */}
      <div className="flex flex-wrap gap-2">
        {quickPrompts.map((qp) => (
          <Button
            key={qp.label}
            variant="outline"
            size="sm"
            onClick={() => handleAskAI(qp.prompt)}
            disabled={loading}
          >
            {qp.label}
          </Button>
        ))}
      </div>

      {/* Prompt Input */}
      <div className="space-y-2">
        <Textarea
          placeholder="Ask the AI assistant..."
          value={prompt}
          onChange={(e) => setPrompt(e.target.value)}
          className="min-h-[100px]"
          disabled={loading}
        />
        <div className="flex items-center justify-between">
          <span className="text-xs text-gray-400">
            {remaining === 'unlimited'
              ? 'Unlimited requests'
              : `${remaining}/10 requests left`}
          </span>
          <Button onClick={() => handleAskAI()} disabled={loading || !prompt.trim()}>
            {loading ? 'Asking...' : 'Ask AI'}
          </Button>
        </div>
      </div>

      {/* Response */}
      {response && (
        <div className="space-y-2">
          <div className="p-4 bg-gray-900 rounded-lg border border-gray-800 max-h-[400px] overflow-y-auto">
            <ReactMarkdown className="prose prose-invert prose-sm max-w-none">
              {response}
            </ReactMarkdown>
          </div>

          <div className="flex gap-2">
            <Button variant="outline" size="sm" onClick={handleCopyToClipboard}>
              Copy
            </Button>
            <Button variant="outline" size="sm" onClick={handleSendToChat}>
              Send to Chat
            </Button>
          </div>
        </div>
      )}
    </div>
  );
}
```

### Prisma Schema Addition
**[Source: Architecture Section 4.8 - AIUsage Model]**

```prisma
model AIUsage {
  id         String   @id @default(cuid())
  userId     String
  tableId    String?
  prompt     String
  response   String   @db.Text
  tokensUsed Int
  cost       Float    // In dollars
  createdAt  DateTime @default(now())

  user  User   @relation(fields: [userId], references: [id], onDelete: Cascade)
  table Table? @relation(fields: [tableId], references: [id], onDelete: SetNull)

  @@index([userId, createdAt])
  @@index([tableId])
}
```

### Environment Variables
```bash
# .env
ANTHROPIC_API_KEY=sk-ant-...
```

### Testing

**Test scenarios:**
- DM can access AI assistant panel
- Non-DMs cannot see AI assistant
- AI responds with relevant suggestions
- Streaming displays response word-by-word
- Quick prompt buttons work
- Copy to clipboard works
- Send to chat posts as DM message
- Rate limiting enforces 10 requests/hour for free tier
- Premium users have unlimited requests
- AI usage tracked in database with cost
- Context includes table, characters, messages
- Errors handled gracefully

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-09-30 | 1.0 | Initial story draft | Bob (SM) |

## Dev Agent Record
_To be filled by dev agent_

## QA Results
_To be filled by QA agent_
